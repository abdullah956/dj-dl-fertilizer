{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-26T05:26:05.141733Z",
     "iopub.status.busy": "2022-02-26T05:26:05.141393Z",
     "iopub.status.idle": "2022-02-26T05:26:05.152156Z",
     "shell.execute_reply": "2022-02-26T05:26:05.151168Z",
     "shell.execute_reply.started": "2022-02-26T05:26:05.141699Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing required libraries.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:26:05.154826Z",
     "iopub.status.busy": "2022-02-26T05:26:05.154458Z",
     "iopub.status.idle": "2022-02-26T05:26:05.164696Z",
     "shell.execute_reply": "2022-02-26T05:26:05.163261Z",
     "shell.execute_reply.started": "2022-02-26T05:26:05.154793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing crop images from location.\n",
    "\n",
    "path1 = os.listdir(r\"C:\\Users\\PMLS\\Desktop\\Projects\\data science\\Crop-Prediction-Using-CNN\\Crop_Dataset\\crop_images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:26:05.166013Z",
     "iopub.status.busy": "2022-02-26T05:26:05.165766Z",
     "iopub.status.idle": "2022-02-26T05:26:05.179350Z",
     "shell.execute_reply": "2022-02-26T05:26:05.178743Z",
     "shell.execute_reply.started": "2022-02-26T05:26:05.165981Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing tensorflow for image procesing\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:26:05.185336Z",
     "iopub.status.busy": "2022-02-26T05:26:05.181189Z",
     "iopub.status.idle": "2022-02-26T05:26:05.189374Z",
     "shell.execute_reply": "2022-02-26T05:26:05.188763Z",
     "shell.execute_reply.started": "2022-02-26T05:26:05.185300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data generation and formatting the data.\n",
    "\n",
    "data_gen=ImageDataGenerator(shear_range=0.2,zoom_range=0.2,horizontal_flip=True,rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:29:30.470774Z",
     "iopub.status.busy": "2022-02-26T05:29:30.470346Z",
     "iopub.status.idle": "2022-02-26T05:29:30.813593Z",
     "shell.execute_reply": "2022-02-26T05:29:30.812769Z",
     "shell.execute_reply.started": "2022-02-26T05:29:30.470738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 201 images belonging to 5 classes.\n",
      "Found 804 images belonging to 5 classes.\n",
      "Found 50 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training data for checking accuracy\n",
    "train_data1 = data_gen.flow_from_directory(\n",
    "    r\"C:\\Users\\PMLS\\Desktop\\Projects\\data science\\Crop-Prediction-Using-CNN\\Crop_Dataset\\crop_images\",\n",
    "    target_size=(150,150)\n",
    ")\n",
    "\n",
    "train_data2 = data_gen.flow_from_directory(\n",
    "    r\"C:\\Users\\PMLS\\Desktop\\Projects\\data science\\Crop-Prediction-Using-CNN\\Crop_Dataset\\kag2\",\n",
    "    target_size=(150,150)\n",
    ")\n",
    "\n",
    "train_data3 = data_gen.flow_from_directory(\n",
    "    r\"C:\\Users\\PMLS\\Desktop\\Projects\\data science\\Crop-Prediction-Using-CNN\\Crop_Dataset\\some_more_images\",\n",
    "    target_size=(150,150)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:29:35.267386Z",
     "iopub.status.busy": "2022-02-26T05:29:35.266831Z",
     "iopub.status.idle": "2022-02-26T05:29:35.271633Z",
     "shell.execute_reply": "2022-02-26T05:29:35.270938Z",
     "shell.execute_reply.started": "2022-02-26T05:29:35.267345Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries for model building\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:29:37.073807Z",
     "iopub.status.busy": "2022-02-26T05:29:37.073077Z",
     "iopub.status.idle": "2022-02-26T05:29:37.141320Z",
     "shell.execute_reply": "2022-02-26T05:29:37.140662Z",
     "shell.execute_reply.started": "2022-02-26T05:29:37.073766Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN model generation\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(16,(3,3),padding='same',activation='relu',input_shape=(150,150,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(32,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:37:22.441810Z",
     "iopub.status.busy": "2022-02-26T05:37:22.441532Z",
     "iopub.status.idle": "2022-02-26T05:40:40.012138Z",
     "shell.execute_reply": "2022-02-26T05:40:40.011438Z",
     "shell.execute_reply.started": "2022-02-26T05:37:22.441779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.2372 - loss: 170278.3594\n",
      "Epoch 2/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.1786 - loss: 108090.5547\n",
      "Epoch 3/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.1957 - loss: 100943.6797\n",
      "Epoch 4/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.2254 - loss: 97506.0391\n",
      "Epoch 5/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.2531 - loss: 109176.1562\n",
      "Epoch 6/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.2111 - loss: 101831.1562\n",
      "Epoch 7/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.2184 - loss: 111885.1484\n",
      "Epoch 8/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.2838 - loss: 71826.2969\n",
      "Epoch 9/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.2530 - loss: 75025.1797\n",
      "Epoch 10/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.2644 - loss: 76416.6250\n",
      "Epoch 11/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.2684 - loss: 80614.8359\n",
      "Epoch 12/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.2332 - loss: 76983.7656\n",
      "Epoch 13/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.2109 - loss: 73882.8047\n",
      "Epoch 14/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.2247 - loss: 55122.6016\n",
      "Epoch 15/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.3150 - loss: 42151.9727 \n",
      "Epoch 16/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.2294 - loss: 43185.0234\n",
      "Epoch 17/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.1755 - loss: 66873.2344\n",
      "Epoch 18/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.2686 - loss: 28563.7793\n",
      "Epoch 19/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.2422 - loss: 24456.8555\n",
      "Epoch 20/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.2635 - loss: 18556.2344\n",
      "Epoch 21/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.2487 - loss: 17798.4688\n",
      "Epoch 22/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.2434 - loss: 15198.9014\n",
      "Epoch 23/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.2708 - loss: 6803.6909\n",
      "Epoch 24/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.2659 - loss: 5180.1396\n",
      "Epoch 25/25\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.2336 - loss: 5900.5796\n",
      "Epoch 1/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.3123 - loss: 2352.5776\n",
      "Epoch 2/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.3025 - loss: 515.4283\n",
      "Epoch 3/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.3812 - loss: 85.4194\n",
      "Epoch 4/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 233ms/step - accuracy: 0.4206 - loss: 29.7285\n",
      "Epoch 5/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 204ms/step - accuracy: 0.5102 - loss: 8.7187\n",
      "Epoch 6/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 309ms/step - accuracy: 0.5876 - loss: 2.7777\n",
      "Epoch 7/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - accuracy: 0.6487 - loss: 1.3710\n",
      "Epoch 8/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.7180 - loss: 0.7843\n",
      "Epoch 9/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7708 - loss: 0.6632\n",
      "Epoch 10/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7414 - loss: 0.7757\n",
      "Epoch 11/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.8019 - loss: 0.7993\n",
      "Epoch 12/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8576 - loss: 0.4317\n",
      "Epoch 13/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.8429 - loss: 0.4759\n",
      "Epoch 14/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.8809 - loss: 0.3068\n",
      "Epoch 15/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.8984 - loss: 0.3572\n",
      "Epoch 16/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.8591 - loss: 0.4397\n",
      "Epoch 17/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.9421 - loss: 0.1720\n",
      "Epoch 18/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.9594 - loss: 0.1530\n",
      "Epoch 19/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.9227 - loss: 0.2024\n",
      "Epoch 20/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.9681 - loss: 0.0993\n",
      "Epoch 21/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - accuracy: 0.9238 - loss: 0.3006\n",
      "Epoch 22/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.9803 - loss: 0.0746\n",
      "Epoch 23/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.9789 - loss: 0.1463\n",
      "Epoch 24/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.9741 - loss: 0.0800\n",
      "Epoch 25/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.9777 - loss: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18c9766d070>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN model training\n",
    "\n",
    "model.fit(train_data1,epochs=25)\n",
    "model.fit(train_data2,epochs=25)\n",
    "# model.fit(train_data3,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-26T05:26:05.233118Z",
     "iopub.status.idle": "2022-02-26T05:26:05.233579Z",
     "shell.execute_reply": "2022-02-26T05:26:05.233406Z",
     "shell.execute_reply.started": "2022-02-26T05:26:05.233386Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('crop_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jute': 0, 'maize': 1, 'rice': 2, 'sugarcane': 3, 'wheat': 4}\n"
     ]
    }
   ],
   "source": [
    "print(train_data1.class_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
